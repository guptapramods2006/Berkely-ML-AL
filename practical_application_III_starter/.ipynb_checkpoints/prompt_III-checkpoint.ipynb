{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below Code represent there are total 42 Marketing campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data represents 42 marketing campaigns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/bank-additional-full.csv', sep = ';')\n",
    "df.head()\n",
    "num_campaigns = df['campaign'].nunique()\n",
    "print(f\"The data represents {num_campaigns} marketing campaigns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To check dataset, used following Panda functions\n",
    "\n",
    "For checking missing values: df.isnull().sum()\n",
    "For data type checking: df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4 ) Understanding the Task\n",
    "\n",
    "The business objective of this project is to leverage historical marketing campaign data to develop a predictive model that can assist the marketing department of the bank in maximizing the success of their future marketing campaigns. The goal is to identify the most promising target audience and optimize campaign strategies to increase the conversion rate of clients subscribing to term deposits, ultimately improving the bank's revenue and efficiency of marketing efforts.\n",
    "\n",
    "Key components of this business objective include:\n",
    "=========================================\n",
    "\n",
    "Predictive Model: Build a machine learning model that can predict the likelihood of a client subscribing to a term deposit based on various client attributes and campaign details.\n",
    "\n",
    "Marketing Campaign Optimization: Use the insights from the predictive model to target the right audience segments with tailored marketing strategies. This may involve optimizing the timing, communication channels, and content of marketing campaigns.\n",
    "\n",
    "Revenue Increase: The primary objective is to increase the bank's revenue by boosting the subscription rate for term deposits, leading to more successful marketing campaigns.\n",
    "\n",
    "Efficiency Improvement: Ensure that marketing efforts are optimized to use resources effectively and reduce marketing costs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope (Coefficient): 0.6\n",
      "Intercept: 2.2\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data (x, y)\n",
    "x = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # Input features (reshaped for single feature)\n",
    "y = np.array([2, 4, 5, 4, 5])  # Target variable\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(x, y)\n",
    "\n",
    "# Make predictions\n",
    "x_test = np.array([6, 7, 8]).reshape(-1, 1)  # New data points for prediction\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Plot the data and regression line\n",
    "plt.scatter(x, y, color='b', label='Data points')\n",
    "plt.plot(x_test, y_pred, color='r', label='Regression line')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the coefficients (slope and intercept)\n",
    "print(f\"Slope (Coefficient): {model.coef_[0]}\")\n",
    "print(f\"Intercept: {model.intercept_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features (columns 1 - 7), prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5) Need to handle both numerical and categorical data appropriately. \n",
    "\n",
    "Encoding Categorical Features: \n",
    "Columns 1 to 7 include some categorical features (e.g., job, marital, education, default, housing, loan, and contact). Used one-hot encoding to convert these categorical variables into a format that the machine learning model can use.\n",
    "\n",
    "Selecting the Target Column: \n",
    "The target variable is typically a binary outcome, which is mentioned to be column 20, 'y' (has the client subscribed a term deposit?). So selected this column as target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('data/bank-additional-full.csv', sep=';')\n",
    "\n",
    "# Select features and target\n",
    "features = df[['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact']]\n",
    "target = df['y']  # Target variable\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "features_encoded = pd.get_dummies(features, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact'])\n",
    "\n",
    "# Now, features_encoded contains the encoded features, and target contains the target variable.\n",
    "# Use these in your machine learning model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Train/Test Split\n",
    "To split data into a training set and a test set for machine learning,use the train_test_split function from the scikit-learn library. This function will randomly divide dataset into two subsets: one for training the model and the other for evaluating its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train: Features for training\n",
    "# X_test: Features for testing\n",
    "# y_train: Target variable for training\n",
    "# y_test: Target variable for testing\n",
    "\n",
    "# The 'test_size' parameter specifies the proportion of data to allocate to the test set (in this case, 20%).\n",
    "\n",
    "# 'random_state' is set to ensure reproducibility. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) A Baseline Model\n",
    "\n",
    "The baseline typically serves as a reference point for evaluating the performance of more complex models. For classification tasks, a common baseline is to use a simple rule, such as predicting the most frequent class in the training data.\n",
    "\n",
    "In the context of your classification task (predicting whether a client subscribes to a term deposit), the baseline can be defined as follows:\n",
    "\n",
    "Baseline Performance: The baseline performance for the classifier should be the accuracy achieved by a simple rule, where all predictions are made by selecting the majority class in the training data.\n",
    "\n",
    "To implement this baseline performance measurement, follow these steps:\n",
    "\n",
    "Calculate the distribution of the target variable in the training data to determine the majority class.\n",
    "Predict the majority class for all instances in the test data.\n",
    "Calculate the accuracy of these predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate the majority class in the training data\n",
    "majority_class = y_train.value_counts().idxmax()\n",
    "\n",
    "# Create an array of predictions where all instances are the majority class\n",
    "baseline_predictions = [majority_class] * len(y_test)\n",
    "\n",
    "# Calculate the baseline accuracy\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_predictions)\n",
    "\n",
    "print(f\"Baseline Accuracy: {baseline_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Model\n",
    "\n",
    "Logistic Regression is a suitable choice for building a basic classification model for data. Here's how you can build a simple Logistic Regression model using scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "#model = LogisticRegression()\n",
    "#model = LogisticRegression(solver='saga')  # Try using a different solver\n",
    "model = LogisticRegression(max_iter=1000)  # Increase the number of iterations\n",
    "\n",
    "\n",
    "# Fit the model on the training data\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "#y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Then train the model with the scaled data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Score the Model\n",
    "\n",
    "To calculate the accuracy of your Logistic Regression model, you can use the scikit-learn accuracy_score function, which compares the model's predictions to the true labels. Here's how to compute the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression model: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate the accuracy of the model's predictions on the test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of the Logistic Regression model: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10)  Model Comparisons\n",
    "\n",
    "To compare the performance of multiple machine learning models, including Logistic Regression, K-Nearest Neighbors (KNN), Decision Tree, and Support Vector Machine (SVM), used the scikit-learn library and create a table to present  findings. Here's a step-by-step approach on how to do this:\n",
    "\n",
    "1. Import the necessary libraries and models.\n",
    "2. Train each model on the training data and evaluate their accuracy on both the training and test data.\n",
    "3. Measure and compare the training time for each model.\n",
    "4. Create a table to present the findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Train Time  Train Accuracy  Test Accuracy\n",
      "0  Logistic Regression    0.553314        0.887557       0.886502\n",
      "1                  KNN    0.033193        0.894082       0.873392\n",
      "2        Decision Tree    0.126845        0.924219       0.854819\n",
      "3                  SVM   16.886789        0.887557       0.886502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),  # Increase max_iter if needed\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVM': SVC(),\n",
    "}\n",
    "\n",
    "# Initialize lists to store results\n",
    "model_names = []\n",
    "train_times = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    # Append results to the lists\n",
    "    model_names.append(model_name)\n",
    "    train_times.append(train_time)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Create a DataFrame to present the findings\n",
    "results = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Train Time': train_times,\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Test Accuracy': test_accuracies\n",
    "})\n",
    "\n",
    "# Print the results\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11) Improving the Model\n",
    "Improving machine learning models is an essential part of the process. Here are some strategies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering and exploration :\n",
    "\n",
    "Feature Selection: Evaluate the importance of features and consider removing or adding relevant features. You can use techniques like feature importance scores from tree-based models or correlation analysis to identify important features.\n",
    "\n",
    "Categorical Variables: For categorical features, consider one-hot encoding or using techniques like target encoding.\n",
    "\n",
    "Handling Missing Values: Deal with missing values in a meaningful way, which may involve imputation or feature engineering to capture the missingness.\n",
    "Feature Scaling: Standardize or normalize numerical features, as some algorithms are sensitive to feature scales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "Use techniques like grid search or random search to find the optimal hyperparameters for your models.\n",
    "\n",
    "For K-Nearest Neighbors (KNN), explore different values of K, distance metrics, and weighting schemes.\n",
    "\n",
    "For Decision Trees, adjust hyperparameters like maximum depth, minimum samples per leaf, and criterion (e.g., Gini or entropy).\n",
    "\n",
    "For Support Vector Machines (SVM), experiment with different kernels (e.g., linear, polynomial, or radial basis function) and the regularization parameter (C)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "Consider trying more advanced models, such as Random Forest, Gradient Boosting, or Neural Networks, to see if they offer improved performance.\n",
    "\n",
    "Ensemble methods like Random Forest or Gradient Boosting can often provide better accuracy by combining multiple weak learners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics\n",
    "\n",
    "Depending on the business objective, consider using different performance metrics. For instance, if class imbalance is an issue, focus on metrics like precision, recall, F1-score, or area under the ROC curve (AUC) rather than just accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that model improvement is an iterative process. You should experiment with different approaches and evaluate their impact on model performance. Keep track of the changes you make and document the results to guide your decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
